{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy necessary to do basic data cleaning\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './aer_data/aer_data.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4e1137c336cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./aer_data/aer_data.dta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Clean up data types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, storage_options)\u001b[0m\n\u001b[0;32m   1896\u001b[0m ) -> Union[DataFrame, StataReader]:\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m     reader = StataReader(\n\u001b[0m\u001b[0;32m   1899\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m         \u001b[0mconvert_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buf, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, storage_options)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_native_byteorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_endianness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './aer_data/aer_data.dta'"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "df = pd.read_stata(\"./aer_data/aer_data.dta\")\n",
    "\n",
    "# Clean up data types\n",
    "df['year'] = df.year.dt.year\n",
    "for x in ['year','fips','stfips']:\n",
    "    df[x] = df[x].astype(int)\n",
    "\n",
    "# Filter data the same as paper authors\n",
    "df = df[df.year <= 1988]\n",
    "df = df[~((df.stfips == 36) & (df.cofips == 61))] \n",
    "df = df[~((df.stfips == 6) & (df.cofips == 37))]\n",
    "df = df[~((df.stfips == 17) & (df.cofips == 31))]\n",
    "\n",
    "# Make new variables related to urbanization\n",
    "df_1960_pcturban = df.loc[df.year == 1960, ['fips','D_60pcturban_t']] \\\n",
    "                     .drop_duplicates('fips') \\\n",
    "                     .rename(columns={'D_60pcturban_t':'_urb'}) \\\n",
    "                     .fillna(0)\n",
    "df = df.merge(df_1960_pcturban, how='left', on='fips')\n",
    "df['Durb'] = pd.cut(x=df._urb, bins=[0,1,25,50,75,110], right=False, labels=[0,1,25,50,75])\n",
    "\n",
    "# Make straight-up dummy variables\n",
    "year_dummies   = pd.get_dummies(df.year, prefix=\"_Iyear\", drop_first=True)\n",
    "Durb_dummies   = pd.get_dummies(df.Durb, prefix=\"_IDurb\", drop_first=True)\n",
    "fips_dummies   = pd.get_dummies(df.fips, prefix=\"_Ifips\", drop_first=True)\n",
    "stfips_dummies = pd.get_dummies(df.stfips, prefix=\"_Istfips\", drop_first=True)\n",
    "\n",
    "# Make interaction dummies\n",
    "for year in np.sort(df.year.unique()):\n",
    "    for Durb in np.sort(df.Durb.unique()):\n",
    "        if (f\"_Iyear_{year}\" in year_dummies.columns) & (f\"_IDurb_{Durb}\" in Durb_dummies.columns):\n",
    "            df[f\"_IyeaXDur_{year}_{Durb}\"] = year_dummies[f\"_Iyear_{year}\"]*Durb_dummies[f\"_IDurb_{Durb}\"]\n",
    "    for stfips in np.sort(df.stfips.unique()):\n",
    "        if (f\"_Iyear_{year}\" in year_dummies.columns) & (f\"_Istfips_{stfips}\" in stfips_dummies.columns):\n",
    "            df[f\"_IyeaXstf_{year}_{stfips}\"] = year_dummies[f\"_Iyear_{year}\"]*stfips_dummies[f\"_Istfips_{stfips}\"]\n",
    "for fips in np.sort(df.fips.unique()):\n",
    "    df[f\"_IfipXyea_{fips}\"] = np.where((df['fips']) == fips, df['year'], 0)\n",
    "\n",
    "# Make did1 dummies\n",
    "for i,did1 in enumerate(np.sort(df.did1.unique())):\n",
    "    if did1 != -1:\n",
    "        df[f\"_DDdid1_{i+1}\"] = np.where(df['did1'] == did1, 1, 0)\n",
    "\n",
    "# Add on year and fips dummies\n",
    "df = pd.concat([df,year_dummies],axis=1)\n",
    "df = pd.concat([df,fips_dummies],axis=1)\n",
    "\n",
    "# Drop missing response values\n",
    "df = df[~df['amr'].isna()]\n",
    "\n",
    "# Add constant\n",
    "df['_const']  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY_arrays(df,X_cols,Y_var,weight_var):\n",
    "\n",
    "    # Make arrays \n",
    "    Y      = df[Y_var].to_numpy()[:,None]\n",
    "    X      = df[X_cols].to_numpy()\n",
    "    weight = df[weight_var].to_numpy()[:,None]\n",
    "\n",
    "    return Y,X,weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1d7e0c2377eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define covariates to use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_Ifips_cols\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_Ifips'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0m_Iyear_cols\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_Iyear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0m_IyeaXDu_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_IyeaXDu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_DD_cols\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_DD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define covariates to use\n",
    "_Ifips_cols   = [col for col in df if col.startswith('_Ifips')]\n",
    "_Iyear_cols   = [col for col in df if col.startswith('_Iyear')]\n",
    "_IyeaXDu_cols = [col for col in df if col.startswith('_IyeaXDu')]\n",
    "_DD_cols      = [col for col in df if col.startswith('_DD')]\n",
    "X_cols        = _Ifips_cols+_Iyear_cols+_IyeaXDu_cols+_DD_cols+['_const'] \n",
    "Y_var         = 'amr'\n",
    "weight_var    = 'popwt'\n",
    "\n",
    "Y,X,weight = make_regression_matrices(df,X_cols,Y_var,weight_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Coefficient and SE Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fe_weighted_regression(y,X,w_popwt,df):\n",
    "    \n",
    "    # Get beta value\n",
    "    beta = np.linalg.pinv(np.multiply(X,w_popwt).T @ X) @ np.multiply(X,w_popwt).T @ y\n",
    "\n",
    "    # Build the 'meat' of the cluster sandwich SE estimator\n",
    "    clust_cov_sum = np.zeros((len(beta),len(beta)))\n",
    "    for clust in np.sort(df.fips.unique()):\n",
    "\n",
    "        # Define data just from cluster\n",
    "        df_clust = df[df.fips == clust]\n",
    "        X_clust  = df_clust[X_cols].to_numpy()\n",
    "        y_clust  = df_clust['amr'].to_numpy()[:,None]\n",
    "        w_popwt_clust = df_clust['popwt'].to_numpy()[:,None]\n",
    "\n",
    "        # Do weighted cluster robust SE formula\n",
    "        u_j  = np.multiply((y_clust - X_clust @ beta), X_clust)\n",
    "        wu_j = np.multiply(w_popwt_clust, u_j)\n",
    "        clust_sum = np.sum(wu_j, axis=0)[None,:]\n",
    "        clust_cov = clust_sum.T @ clust_sum\n",
    "\n",
    "        # Add to overall \n",
    "        clust_cov_sum += clust_cov\n",
    "\n",
    "    # Get (X'X)^(-1): the 'bread' of the sandwich\n",
    "    vcov = np.linalg.pinv(np.multiply(X,w_popwt).T @ X)\n",
    "    vcov = np.where(vcov < 0, 0, vcov)\n",
    "\n",
    "    # Finite-sample correction\n",
    "    n_clust = df.fips.unique().shape[0]\n",
    "    N       = np.sum(df['popwt'])\n",
    "    k       = beta.shape[0]\n",
    "    qc      = (n_clust/(n_clust-1)) * (N/(N-k))\n",
    "\n",
    "    # Get standard errors of betas\n",
    "    SE = np.sqrt(np.diag(qc * vcov @ clust_cov_sum @ vcov))\n",
    "    \n",
    "    return beta,vcov,SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta,vcov,SE = run_fe_weighted_regression(y,X,w_popwt,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results in Table and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        beta_name  beta_values    beta_se\n",
      "3061  _Iyear_1960    12.672612  26.253466\n",
      "3062  _Iyear_1961   -15.191984  25.961281\n",
      "3063  _Iyear_1962     7.382851  27.877679\n",
      "3064  _Iyear_1963    25.784916  31.001602\n",
      "3065  _Iyear_1964     2.305644  38.843589\n",
      "3066  _Iyear_1965     0.061686  35.270078\n",
      "3067  _Iyear_1966    -0.821723  36.798754\n",
      "3068  _Iyear_1967   -16.789440  37.756279\n",
      "3069  _Iyear_1968     1.279656  41.673243\n",
      "3070  _Iyear_1969    -2.463052  42.303299\n",
      "3071  _Iyear_1970   -26.824601  40.544035\n",
      "3072  _Iyear_1971   -50.165184  43.566103\n",
      "3073  _Iyear_1972   -47.168861  44.770084\n",
      "3074  _Iyear_1973   -56.113462  48.548970\n",
      "3075  _Iyear_1974  -105.138011  45.283146\n",
      "              beta_name  beta_values    beta_se\n",
      "3198   _IyeaXDur_1987_1   -12.613402  57.973286\n",
      "3199  _IyeaXDur_1987_25   -11.973542  57.578462\n",
      "3200  _IyeaXDur_1987_50   -16.232936  58.899123\n",
      "3201  _IyeaXDur_1987_75   -18.219819  62.532406\n",
      "3202   _IyeaXDur_1988_1   -12.366518  59.497630\n",
      "3203  _IyeaXDur_1988_25   -14.603190  59.123421\n",
      "3204  _IyeaXDur_1988_50   -20.891239  60.542477\n",
      "3205  _IyeaXDur_1988_75   -20.716013  64.231034\n",
      "3206          _DDdid1_1     3.872314   4.971656\n",
      "3207          _DDdid1_2     0.033880   3.135779\n",
      "3208          _DDdid1_4    -5.636439   3.758693\n",
      "3209          _DDdid1_5   -12.045204   5.261462\n",
      "3210          _DDdid1_6    -9.384156   6.971082\n",
      "3211          _DDdid1_7    -9.166914  10.232743\n",
      "3212             _const  1019.556930   0.024384\n"
     ]
    }
   ],
   "source": [
    "beta_table = pd.DataFrame.from_dict({\"beta_name\":X_cols,\n",
    "                                     \"beta_values\":beta.ravel(),\n",
    "                                     \"beta_se\":SE})\n",
    "beta_table = beta_table[~beta_table.beta_name.str.contains('^_Ifips_')]\n",
    "print(beta_table.head(15))\n",
    "print(beta_table.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "beta_table = beta_table[beta_table.beta_name.str.contains('^_DDdid1_')]\n",
    "beta_table.to_csv('table2_replication.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
