{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy necessary to do basic data cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_stata(\"./qje_data/Dataset_QJE_Replicate_with_Cities.dta\")\n",
    "df['_const'] = 1\n",
    "\n",
    "# Replicate existence variable\n",
    "df['exist1349']   = np.where((df['judaica'] == 1) | (df['comm1349'] == 1), 1, 0)\n",
    "\n",
    "# Population controls\n",
    "df['pop33']       = np.where(df['pop33'].isna(), df['n333pop'], df['pop33'])\n",
    "df['pop245']      = np.where(df['n245pop'].isna(), (df['c25pop']/df['c33pop1'])*df['pop33'], df['n245pop'])\n",
    "df['logpop25c']   = np.log(df['c25pop'])\n",
    "df['logpop33c']   = np.log(df['c33pop1'])\n",
    "df['logpop33_dep']= np.log(df['pop33'])\n",
    "df['logpop245']   = np.log(df['n245pop'])\n",
    "df['logpop285']   = np.log(df['n285pop'])\n",
    "df['logpop309']   = np.log(df['n309pop'])\n",
    "df['logpop333']   = np.log(df['n333pop'])\n",
    "df['logpop1300']  = np.log(1000*df['pop_1300'])\n",
    "df['logpop1500']  = np.log(1000*df['pop_1500'])\n",
    "df['logpop1750']  = np.log(1000*df['pop_1750'])\n",
    "\n",
    "# Number and share religion controls\n",
    "df['perc_PROT25'] = 100*(df['c25prot']/df['c25pop'])\n",
    "df['perc_CAT25']  = 100*(df['c25kath']/df['c25pop'])\n",
    "df['perc_JEW25']  = 100*(df['c25juden']/df['c25pop'])\n",
    "df['perc_JEW33']  = np.where((100*(df['jews33']/df['pop33'])).isna() | (100*(df['jews33']/df['pop33'])) == 1, \n",
    "                             df['perc_JEW25'], (100*(df['jews33']/df['pop33'])))\n",
    "df['logjews25']   = np.log(1+df['c25juden'])\n",
    "df['logjews33']   = np.log(1+df['jews33'])\n",
    "df['logjews39']   = np.log(1+df['jews39'])\n",
    "\n",
    "# Labor market controls\n",
    "df['perc_Unemp33']  = 100*(df['c33erlos']/df['c33erwp'])\n",
    "df['perc_Blue25']   = 100*(df['c25arbei']/df['c25berwt'])\n",
    "df['perc_Blue33']   = 100*((df['c33arbei']+df['c33eloar'])/df['c33erwp'])\n",
    "df['perc_Ag25']     = 100*(df['c25bland']/df['c25berwt'])\n",
    "df['perc_Ag33']     = 100*(df['c33land']/df['c33erwtt'])\n",
    "df['perc_Ind25']    = 100*(df['c25bwerk']/df['c25berwt'])\n",
    "df['perc_Ind33']    = 100*(df['c33indu']/df['c33erwtt'])\n",
    "df['perc_self25']   = 100*(df['c25selb']/df['c25berwt'])\n",
    "df['perc_self33']   = 100*(df['c33selb']/df['c33erwtt'])\n",
    "df['perc_RT25']     = 100*(df['c25bhand']/df['c25berwt'])\n",
    "df['perc_RT33']     = 100*(df['c33hndl']/df['c33erwtt'])\n",
    "df['perc_selfRT25'] = 100*(df['c25hselb']/df['c25bhand'])\n",
    "df['perc_Ind25']    = np.where(df['perc_Ind25'].isna(), df['perc_Ind33'], df['perc_Ind25'])\n",
    "df['perc_Blue25']   = np.where(df['perc_Blue25'].isna(), df['perc_Blue33'], df['perc_Blue25'])\n",
    "df['perc_Ag25']     = np.where(df['perc_Ag25'].isna(), df['perc_Ag33'], df['perc_Ag25'])\n",
    "df['perc_selfRT25'] = np.where(df['perc_selfRT25'].isna(), df['perc_self33'], df['perc_selfRT25'])\n",
    "df['hephep_all']    = df['hephep']+df['hephep_instigated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY_arrays(df,X_cols,Y_var,treat_var):\n",
    "    \n",
    "    # Exclude those with missing data\n",
    "    reg_df = df[df['exist1349'] == 1]\n",
    "    for var in [Y_var]+X_cols:\n",
    "        reg_df = reg_df[~reg_df[var].isna()]\n",
    "    reg_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Make XY arrays\n",
    "    X          = np.array(reg_df[X_cols])\n",
    "    Y          = np.array(reg_df[Y_var])[:,None]\n",
    "    treatments = np.array(reg_df[treat_var])\n",
    "    N          = X.shape[0]\n",
    "    K          = X.shape[1]\n",
    "    \n",
    "    return reg_df,X,Y,treatments,N,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols    = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','_const']\n",
    "Y_var     = 'pog20s'\n",
    "clust_var = 'kreis_nr'\n",
    "treat_var = 'pog1349'\n",
    "\n",
    "reg_df,X,Y,treatments,N,K = get_XY_arrays(df,X_cols,Y_var,treat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(b) - Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel A - Imputation Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qje_regression(X,Y,reg_df,X_cols,Y_var,clust_var,N,K):\n",
    "    \n",
    "    # Get beta first\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    \n",
    "    # Build the 'meat' of the cluster sandwich SE estimator\n",
    "    clust_cov_sum = np.zeros((K,K))\n",
    "    for clust in np.sort(reg_df[clust_var].unique()):\n",
    "\n",
    "        # Define data just from that cluster\n",
    "        df_clust = reg_df[reg_df[clust_var] == clust]\n",
    "        X_clust  = df_clust[X_cols].to_numpy()\n",
    "        y_clust  = df_clust[Y_var].to_numpy()[:,None]\n",
    "\n",
    "        # Do cluster robust SE formula\n",
    "        u_j       = (y_clust - X_clust @ beta)\n",
    "        clust_cov = X_clust.T @ u_j @ u_j.T @ X_clust\n",
    "        clust_cov_sum += clust_cov\n",
    "\n",
    "    # Get (X'X)^(-1): the 'bread' of the sandwich\n",
    "    vcov = np.linalg.pinv(X.T @ X)\n",
    "\n",
    "    # Finite-sample correction\n",
    "    n_clust = reg_df[clust_var].unique().shape[0]\n",
    "    qc      = (n_clust/(n_clust-1))*(N/(N-K))\n",
    "\n",
    "    # Get standard errors of betas\n",
    "    beta_SE = np.sqrt(np.diag(qc * vcov @ clust_cov_sum @ vcov))\n",
    "    return beta.ravel(),beta_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.07025717e-02  3.89553009e-02  1.35080050e-02  3.36759657e-04\n",
      " -3.92747243e-01]\n",
      "[0.02261898 0.01521865 0.01143031 0.00042379 0.13983858]\n"
     ]
    }
   ],
   "source": [
    "beta,beta_SE = run_qje_regression(X,Y,reg_df,X_cols,Y_var,clust_var,N,K)\n",
    "print(beta)\n",
    "print(beta_SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05444318553032268\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "R2    = 1-np.sum((Y - X @ beta[:,None])**2)/np.sum((Y - np.mean(Y))**2)\n",
    "adjR2 = 1-(1-R2)*((N-1)/(N-K))\n",
    "print(adjR2)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel B - Covariate Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Functions for calculating pairwise obs distances\n",
    "def make_dist_matrix(X_match, N, weight_type='inv_diag_vars'):\n",
    "\n",
    "    # Get inverse diagonal variance matrix for weighting\n",
    "    if weight_type == 'inv_diag_vars':\n",
    "        variances = (np.sum((X_match-np.mean(X_match,axis=0))**2,axis=0))/N\n",
    "        weighting = np.linalg.inv(np.diag(variances))\n",
    "    elif weight_type == 'identity':\n",
    "        weighting = np.eye(X_match.shape[1])\n",
    "    \n",
    "    # Populate distance matrix\n",
    "    dist_matrix = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "\n",
    "            # Set own-distance to infinty so it doesn't match to itself\n",
    "            if i == j:\n",
    "                dist_matrix[i,j] = np.inf\n",
    "\n",
    "            # Set distance to obs with same treatment to infinity so they don't match\n",
    "            elif treatments[i] == treatments[j]:\n",
    "                dist_matrix[i,j] = np.inf\n",
    "\n",
    "            # Otherwise allow distance calculation\n",
    "            else:\n",
    "                dist_matrix[i,j] = (\n",
    "                    (X_match[i,:][:,None]-X_match[j,:][:,None]).T @ \n",
    "                    weighting @ \n",
    "                    (X_match[i,:][:,None]-X_match[j,:][:,None])\n",
    "                )[0][0]\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treatment_effect(X_match, dist_matrix, treatments, N_neighbors, N, treatment_params, return_neighbors=False):\n",
    "    \n",
    "    # Get K-th closest neighbor index and value\n",
    "    nth_closest_idx = np.argsort(dist_matrix,axis=1)[:,N_neighbors-1]\n",
    "    nth_closest_val = dist_matrix[np.arange(N), nth_closest_idx]\n",
    "    \n",
    "    # Find obs within distance of nth_closest_val and compute counterfactuals\n",
    "    counterfactual = np.zeros(N)\n",
    "    neighbors_idx_list =[]\n",
    "    for i in range(N):\n",
    "        neighbors_idx = np.argwhere(dist_matrix[i,:] <= nth_closest_val[i]).ravel()\n",
    "        neighbors_idx_list.append(neighbors_idx)\n",
    "        counterfactual[i] = np.mean(Y[neighbors_idx])\n",
    "        \n",
    "    # Calculate treatment effects\n",
    "    treatment_dict = {}\n",
    "    if 'att' in treatment_params:\n",
    "        treated_idx = np.argwhere(treatments==1).ravel()\n",
    "        treatment_dict['att'] = np.mean(Y[treated_idx]-counterfactual[treated_idx])\n",
    "    if 'atu' in treatment_params:\n",
    "        untreated_idx = np.argwhere(treatments==0).ravel()\n",
    "        treatment_dict['atu'] = np.mean(counterfactual[untreated_idx]-Y[untreated_idx])\n",
    "    if 'ate' in treatment_params:\n",
    "        treated_idx   = np.argwhere(treatments==1).ravel()\n",
    "        untreated_idx = np.argwhere(treatments==0).ravel()\n",
    "        att = np.mean(Y[treated_idx]-counterfactual[treated_idx])\n",
    "        atu = np.mean(counterfactual[untreated_idx]-Y[untreated_idx])\n",
    "        treatment_dict['ate'] = np.mean(att*(treated_idx.shape[0]/N) + atu*(untreated_idx.shape[0]/N))\n",
    "    \n",
    "    if not return_neighbors:\n",
    "        return treatment_dict\n",
    "    else:\n",
    "        return treatment_dict,neighbors_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_match_SE(X_match, dist_matrix, treatments, N_neighbors, N, treatment_params, N_boots):\n",
    "    treatment_dict = {i:[] for i in treatment_params}\n",
    "    for i in range(N_boots):\n",
    "        \n",
    "        # Sample observations with replacement and define new X\n",
    "        new_idxs        = np.random.choice(np.arange(N), N)\n",
    "        X_match_new     = X_match[new_idxs,:]\n",
    "        dist_matrix_new = dist_matrix[new_idxs,:]\n",
    "        dist_matrix_new = dist_matrix_new[:,new_idxs]\n",
    "        \n",
    "        # Get treatment effect for this new set\n",
    "        treatment_dict_ind = get_treatment_effect(X_match_new, dist_matrix_new,\n",
    "                                                  treatments, N_neighbors, N,\n",
    "                                                  treatment_params)\n",
    "        for i in treatment_params:\n",
    "            treatment_dict[i].append(treatment_dict_ind[i])\n",
    "    \n",
    "    # Return standard deviation of estimators\n",
    "    return {i:np.std(treatment_dict[i]) for i in treatment_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'att': 0.07435344827586207}\n",
      "{'att': 0.018718738217334736}\n"
     ]
    }
   ],
   "source": [
    "# Remove constant and treatment from X for matching procedures\n",
    "X_matchB = np.array(reg_df[X_cols[1:-1]])\n",
    "\n",
    "# Get results\n",
    "dist_matrixB = make_dist_matrix(X_matchB, N)\n",
    "attB         = get_treatment_effect(X_matchB, dist_matrixB, treatments, 4, N, ['att'])\n",
    "att_seB      = bootstrap_match_SE(X_matchB, dist_matrixB, treatments, 4, N, ['att'], 2500)\n",
    "print(attB)\n",
    "print(att_seB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel C - Distance Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'att': 0.08189655172413793}\n",
      "{'att': 0.026396004262222272}\n"
     ]
    }
   ],
   "source": [
    "# Remove constant and treatment from X for matching procedures\n",
    "X_matchC = np.array(reg_df[['Latitude','Longitude']])\n",
    "\n",
    "# Get results\n",
    "dist_matrixC = make_dist_matrix(X_matchC, N)\n",
    "attC         = get_treatment_effect(X_matchC, dist_matrixC, treatments, 2, N, ['att'])\n",
    "att_seC      = bootstrap_match_SE(X_matchC, dist_matrixC, treatments, 2, N, ['att'], 2500)\n",
    "print(attC)\n",
    "print(att_seC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results to Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regressions and Matching on Various Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols1   = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','perc_CAT25','_const']    # Add Catholics\n",
    "X_cols2   = ['pog1349','logpop33_dep','perc_JEW33','perc_PROT25','perc_CAT25','_const'] # Change to '33 when possible\n",
    "X_cols3   = ['pog1349','perc_JEW25','perc_PROT25','perc_CAT25','_const']                # Only religion variables\n",
    "X_cols4   = ['pog1349','perc_Ag25','perc_Ind25','perc_Blue25','perc_self25','_const']   # Only labor variables\n",
    "X_cols5   = ['pog1349','logpop1300','nav_river','ruggedness20']                         # Only geographic/predetermined\n",
    "X_cols6   = ['pog1349','hephep_all',\n",
    "             'logpop1300','nav_river','ruggedness20','logpop25c',\n",
    "             'perc_JEW25','perc_PROT25','perc_CAT25',\n",
    "             'perc_Ag25','perc_Ind25','perc_Blue25','perc_self25','_const']             # Fully loaded regression\n",
    "X_cols    = [X_cols1,X_cols2,X_cols3,X_cols4,X_cols5,X_cols6]\n",
    "\n",
    "# Loop over all specifications\n",
    "betas         = []\n",
    "beta_SEs      = []\n",
    "Ns            = []\n",
    "match_atts    = []\n",
    "match_att_SEs = []\n",
    "for i in range(len(X_cols)):\n",
    "    \n",
    "    # Get df and XY matrices and parameters\n",
    "    reg_dfi,Xi,Yi,treatmentsi,Ni,Ki = get_XY_arrays(df,X_cols[i],Y_var,treat_var)\n",
    "    Ns.append(Ni)\n",
    "    \n",
    "    # Run regressions and save output\n",
    "    betai,beta_SEi = run_qje_regression(Xi,Yi,reg_dfi,X_cols[i],Y_var,clust_var,Ni,Ki)\n",
    "    betas.append(betai)\n",
    "    beta_SEs.append(beta_SEi)\n",
    "    \n",
    "    # Run matching procedure\n",
    "    X_matchi       = np.array(reg_dfi[X_cols[i][1:-1]])\n",
    "    dist_matrixi   = make_dist_matrix(X_matchi, Ni)\n",
    "    atti           = get_treatment_effect(X_matchi, dist_matrixi, treatmentsi, 4, Ni, ['att'])\n",
    "    att_sei        = bootstrap_match_SE(X_matchC, dist_matrixC, treatmentsi, 4, Ni, ['att'], 500)\n",
    "    match_atts.append(atti)\n",
    "    match_att_SEs.append(att_sei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 320, 320, 177, 46, 42]\n",
      "[0.05708611765011982, 0.050709100339083935, 0.06236892840442213, 0.06728863484750577, 0.2565137601081685, 0.38103602426934335]\n",
      "[0.0225685236072457, 0.0232562871225305, 0.02315088476136828, 0.03781068429574088, 0.10791510796824254, 0.21262522269079773]\n",
      "[0.07327586206896551, 0.07112068965517242, 0.06573275862068965, 0.03515625, 0.09166666666666666, 0.060810810810810814]\n",
      "[0.023192492093808848, 0.023494104054292107, 0.023380263828230385, 0.02983337210185205, 0.09262846122928532, 0.10090539359454886]\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print([Ns[i] for i in range(len(Ns))])\n",
    "print([betas[i][0] for i in range(len(betas))])\n",
    "print([beta_SEs[i][0] for i in range(len(beta_SEs))])\n",
    "print([match_atts[i]['att'] for i in range(len(match_atts))])\n",
    "print([match_att_SEs[i]['att'] for i in range(len(match_att_SEs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results to Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols    = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','_const']\n",
    "Y_var     = 'pog20s'\n",
    "clust_var = 'kreis_nr'\n",
    "treat_var = 'pog1349'\n",
    "\n",
    "reg_df,X,Y,treatments,N,K = get_XY_arrays(df,X_cols,Y_var,treat_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlogit = X[:,1:]\n",
    "Ylogit = X[:,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(beta,Xlogit,Ylogit):\n",
    "    logitval = 1.0 / ( 1.0 + np.exp(-(Xlogit @ beta[:,None])))\n",
    "    return np.sum(Ylogit*np.log(logitval) + (1-Ylogit)*(1-logitval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-193-8c6cf7184d1c>:2: RuntimeWarning: overflow encountered in exp\n",
      "  logitval = 1.0 / ( 1.0 + np.exp(-(Xlogit @ beta[:,None])))\n",
      "<ipython-input-193-8c6cf7184d1c>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(Ylogit*np.log(logitval) + (1-Ylogit)*(1-logitval))\n",
      "<ipython-input-193-8c6cf7184d1c>:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(Ylogit*np.log(logitval) + (1-Ylogit)*(1-logitval))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 0.34773738,  3.39600208, -7.47278986,  0.22411388],\n",
       "       [ 0.34773738,  3.39600208, -7.47278986,  0.22411388],\n",
       "       [ 0.34773738,  3.39600208, -7.47278986,  0.22411388],\n",
       "       [ 0.34773738,  3.39600208, -7.47278986,  0.22411388],\n",
       "       [ 0.34773738,  3.39600208, -7.47278986,  0.22411388]]), array([-inf, -inf, -inf, -inf, -inf]))\n",
       "           fun: -inf\n",
       "       message: 'Maximum number of function evaluations has been exceeded.'\n",
       "          nfev: 803\n",
       "           nit: 176\n",
       "        status: 1\n",
       "       success: False\n",
       "             x: array([ 0.34773738,  3.39600208, -7.47278986,  0.22411388])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.minimize(logistic_log_likelihood, x0=np.zeros(Xlogit.shape[1]), args=(Xlogit,Ylogit), method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-221.8070977791825"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.zeros(Xlogit.shape[1])\n",
    "np.sum(Ylogit * (Xlogit @ beta[:,None]) - np.log(1 + np.exp(Xlogit @ beta[:,None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4988797505635195e-06"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_log_likelihood(np.ones(Xlogit.shape[1]),Xlogit,Ylogit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
