{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy necessary to do basic data cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_stata(\"./qje_data/Dataset_QJE_Replicate_with_Cities.dta\")\n",
    "df['_const'] = 1\n",
    "\n",
    "# Replicate existence variable\n",
    "df['exist1349']   = np.where((df['judaica'] == 1) | (df['comm1349'] == 1), 1, 0)\n",
    "\n",
    "# Population controls\n",
    "df['pop33']       = np.where(df['pop33'].isna(), df['n333pop'], df['pop33'])\n",
    "df['pop245']      = np.where(df['n245pop'].isna(), (df['c25pop']/df['c33pop1'])*df['pop33'], df['n245pop'])\n",
    "df['logpop25c']   = np.log(df['c25pop'])\n",
    "df['logpop33c']   = np.log(df['c33pop1'])\n",
    "df['logpop33_dep']= np.log(df['pop33'])\n",
    "df['logpop245']   = np.log(df['n245pop'])\n",
    "df['logpop285']   = np.log(df['n285pop'])\n",
    "df['logpop309']   = np.log(df['n309pop'])\n",
    "df['logpop333']   = np.log(df['n333pop'])\n",
    "df['logpop1300']  = np.log(1000*df['pop_1300'])\n",
    "df['logpop1500']  = np.log(1000*df['pop_1500'])\n",
    "df['logpop1750']  = np.log(1000*df['pop_1750'])\n",
    "\n",
    "# Number and share religion controls\n",
    "df['perc_PROT25'] = 100*(df['c25prot']/df['c25pop'])\n",
    "df['perc_CAT25']  = 100*(df['c25kath']/df['c25pop'])\n",
    "df['perc_JEW25']  = 100*(df['c25juden']/df['c25pop'])\n",
    "df['perc_JEW33']  = np.where((100*(df['jews33']/df['pop33'])).isna() | (100*(df['jews33']/df['pop33'])) == 1, \n",
    "                             df['perc_JEW25'], (100*(df['jews33']/df['pop33'])))\n",
    "df['logjews25']   = np.log(1+df['c25juden'])\n",
    "df['logjews33']   = np.log(1+df['jews33'])\n",
    "df['logjews39']   = np.log(1+df['jews39'])\n",
    "\n",
    "# Labor market controls\n",
    "df['perc_Unemp33']  = 100*(df['c33erlos']/df['c33erwp'])\n",
    "df['perc_Blue25']   = 100*(df['c25arbei']/df['c25berwt'])\n",
    "df['perc_Blue33']   = 100*((df['c33arbei']+df['c33eloar'])/df['c33erwp'])\n",
    "df['perc_Ag25']     = 100*(df['c25bland']/df['c25berwt'])\n",
    "df['perc_Ag33']     = 100*(df['c33land']/df['c33erwtt'])\n",
    "df['perc_Ind25']    = 100*(df['c25bwerk']/df['c25berwt'])\n",
    "df['perc_Ind33']    = 100*(df['c33indu']/df['c33erwtt'])\n",
    "df['perc_self25']   = 100*(df['c25selb']/df['c25berwt'])\n",
    "df['perc_self33']   = 100*(df['c33selb']/df['c33erwtt'])\n",
    "df['perc_RT25']     = 100*(df['c25bhand']/df['c25berwt'])\n",
    "df['perc_RT33']     = 100*(df['c33hndl']/df['c33erwtt'])\n",
    "df['perc_selfRT25'] = 100*(df['c25hselb']/df['c25bhand'])\n",
    "df['perc_Ind25']    = np.where(df['perc_Ind25'].isna(), df['perc_Ind33'], df['perc_Ind25'])\n",
    "df['perc_Blue25']   = np.where(df['perc_Blue25'].isna(), df['perc_Blue33'], df['perc_Blue25'])\n",
    "df['perc_Ag25']     = np.where(df['perc_Ag25'].isna(), df['perc_Ag33'], df['perc_Ag25'])\n",
    "df['perc_selfRT25'] = np.where(df['perc_selfRT25'].isna(), df['perc_self33'], df['perc_selfRT25'])\n",
    "df['hephep_all']    = df['hephep']+df['hephep_instigated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY_arrays(df,X_cols,Y_var,treat_var):\n",
    "    \n",
    "    # Exclude those with missing data\n",
    "    reg_df = df[df['exist1349'] == 1]\n",
    "    for var in [Y_var]+X_cols:\n",
    "        reg_df = reg_df[~reg_df[var].isna()]\n",
    "    reg_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Make XY arrays\n",
    "    X          = np.array(reg_df[X_cols])\n",
    "    Y          = np.array(reg_df[Y_var])[:,None]\n",
    "    treatments = np.array(reg_df[treat_var])\n",
    "    N          = X.shape[0]\n",
    "    K          = X.shape[1]\n",
    "    \n",
    "    return reg_df,X,Y,treatments,N,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols    = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','_const']\n",
    "Y_var     = 'pog20s'\n",
    "clust_var = 'kreis_nr'\n",
    "treat_var = 'pog1349'\n",
    "\n",
    "reg_df,X,Y,treatments,N,K = get_XY_arrays(df,X_cols,Y_var,treat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(b) - Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel A - Imputation Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qje_regression(X,Y,reg_df,X_cols,Y_var,clust_var,N,K):\n",
    "    \n",
    "    # Get beta first\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    \n",
    "    # Build the 'meat' of the cluster sandwich SE estimator\n",
    "    clust_cov_sum = np.zeros((K,K))\n",
    "    for clust in np.sort(reg_df[clust_var].unique()):\n",
    "\n",
    "        # Define data just from that cluster\n",
    "        df_clust = reg_df[reg_df[clust_var] == clust]\n",
    "        X_clust  = df_clust[X_cols].to_numpy()\n",
    "        y_clust  = df_clust[Y_var].to_numpy()[:,None]\n",
    "\n",
    "        # Do cluster robust SE formula\n",
    "        u_j       = (y_clust - X_clust @ beta)\n",
    "        clust_cov = X_clust.T @ u_j @ u_j.T @ X_clust\n",
    "        clust_cov_sum += clust_cov\n",
    "\n",
    "    # Get (X'X)^(-1): the 'bread' of the sandwich\n",
    "    vcov = np.linalg.pinv(X.T @ X)\n",
    "\n",
    "    # Finite-sample correction\n",
    "    n_clust = reg_df[clust_var].unique().shape[0]\n",
    "    qc      = (n_clust/(n_clust-1))*(N/(N-K))\n",
    "\n",
    "    # Get standard errors of betas\n",
    "    beta_SE = np.sqrt(np.diag(qc * vcov @ clust_cov_sum @ vcov))\n",
    "    return beta.ravel(),beta_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefs and standard errors\n",
    "beta,beta_SE = run_qje_regression(X,Y,reg_df,X_cols,Y_var,clust_var,N,K)\n",
    "\n",
    "# Get adjusted R2\n",
    "R2    = 1-np.sum((Y - X @ beta[:,None])**2)/np.sum((Y - np.mean(Y))**2)\n",
    "adjR2 = 1-(1-R2)*((N-1)/(N-K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel B - Covariate Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Functions for calculating pairwise obs distances\n",
    "def make_dist_matrix(X_match, N, weight_type='inv_diag_vars'):\n",
    "\n",
    "    # Get inverse diagonal variance matrix for weighting\n",
    "    if weight_type == 'inv_diag_vars':\n",
    "        variances = (np.sum((X_match-np.mean(X_match,axis=0))**2,axis=0))/N\n",
    "        weighting = np.linalg.inv(np.diag(variances))\n",
    "    elif weight_type == 'identity':\n",
    "        weighting = np.eye(X_match.shape[1])\n",
    "    \n",
    "    # Populate distance matrix\n",
    "    dist_matrix = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "\n",
    "            # Set own-distance to infinty so it doesn't match to itself\n",
    "            if i == j:\n",
    "                dist_matrix[i,j] = np.inf\n",
    "\n",
    "            # Set distance to obs with same treatment to infinity so they don't match\n",
    "            elif treatments[i] == treatments[j]:\n",
    "                dist_matrix[i,j] = np.inf\n",
    "\n",
    "            # Otherwise allow distance calculation\n",
    "            else:\n",
    "                dist_matrix[i,j] = (\n",
    "                    (X_match[i,:][:,None]-X_match[j,:][:,None]).T @ \n",
    "                    weighting @ \n",
    "                    (X_match[i,:][:,None]-X_match[j,:][:,None])\n",
    "                )[0][0]\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treatment_effect(X_match, dist_matrix, treatments, N_neighbors, N, treatment_params, return_neighbors=False):\n",
    "    \n",
    "    # Get K-th closest neighbor index and value\n",
    "    nth_closest_idx = np.argsort(dist_matrix,axis=1)[:,N_neighbors-1]\n",
    "    nth_closest_val = dist_matrix[np.arange(N), nth_closest_idx]\n",
    "    \n",
    "    # Find obs within distance of nth_closest_val and compute counterfactuals\n",
    "    counterfactual = np.zeros(N)\n",
    "    neighbors_idx_list =[]\n",
    "    for i in range(N):\n",
    "        neighbors_idx = np.argwhere(dist_matrix[i,:] <= nth_closest_val[i]).ravel()\n",
    "        neighbors_idx_list.append(neighbors_idx)\n",
    "        counterfactual[i] = np.mean(Y[neighbors_idx])\n",
    "        \n",
    "    # Calculate treatment effects\n",
    "    treatment_dict = {}\n",
    "    if 'att' in treatment_params:\n",
    "        treated_idx = np.argwhere(treatments==1).ravel()\n",
    "        treatment_dict['att'] = np.mean(Y[treated_idx]-counterfactual[treated_idx])\n",
    "    if 'atu' in treatment_params:\n",
    "        untreated_idx = np.argwhere(treatments==0).ravel()\n",
    "        treatment_dict['atu'] = np.mean(counterfactual[untreated_idx]-Y[untreated_idx])\n",
    "    if 'ate' in treatment_params:\n",
    "        treated_idx   = np.argwhere(treatments==1).ravel()\n",
    "        untreated_idx = np.argwhere(treatments==0).ravel()\n",
    "        att = np.mean(Y[treated_idx]-counterfactual[treated_idx])\n",
    "        atu = np.mean(counterfactual[untreated_idx]-Y[untreated_idx])\n",
    "        treatment_dict['ate'] = np.mean(att*(treated_idx.shape[0]/N) + atu*(untreated_idx.shape[0]/N))\n",
    "    \n",
    "    if not return_neighbors:\n",
    "        return treatment_dict\n",
    "    else:\n",
    "        return treatment_dict,neighbors_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_match_SE(X_match, dist_matrix, treatments, N_neighbors, N, treatment_params, N_boots):\n",
    "    treatment_dict = {i:[] for i in treatment_params}\n",
    "    for i in range(N_boots):\n",
    "        \n",
    "        # Sample observations with replacement and define new X\n",
    "        new_idxs        = np.random.choice(np.arange(N), N)\n",
    "        X_match_new     = X_match[new_idxs,:]\n",
    "        dist_matrix_new = dist_matrix[new_idxs,:]\n",
    "        dist_matrix_new = dist_matrix_new[:,new_idxs]\n",
    "        \n",
    "        # Get treatment effect for this new set\n",
    "        treatment_dict_ind = get_treatment_effect(X_match_new, dist_matrix_new,\n",
    "                                                  treatments, N_neighbors, N,\n",
    "                                                  treatment_params)\n",
    "        for i in treatment_params:\n",
    "            treatment_dict[i].append(treatment_dict_ind[i])\n",
    "    \n",
    "    # Return standard deviation of estimators\n",
    "    return {i:np.std(treatment_dict[i]) for i in treatment_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove constant and treatment from X for matching procedures\n",
    "X_matchB = np.array(reg_df[X_cols[1:-1]])\n",
    "\n",
    "# Get results\n",
    "dist_matrixB = make_dist_matrix(X_matchB, N)\n",
    "attB         = get_treatment_effect(X_matchB, dist_matrixB, treatments, 4, N, ['att'])\n",
    "att_seB      = bootstrap_match_SE(X_matchB, dist_matrixB, treatments, 4, N, ['att'], 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel C - Distance Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove constant and treatment from X for matching procedures\n",
    "X_matchC = np.array(reg_df[['Latitude','Longitude']])\n",
    "\n",
    "# Get results\n",
    "dist_matrixC = make_dist_matrix(X_matchC, N)\n",
    "attC         = get_treatment_effect(X_matchC, dist_matrixC, treatments, 2, N, ['att'])\n",
    "att_seC      = bootstrap_match_SE(X_matchC, dist_matrixC, treatments, 2, N, ['att'], 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results to Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_a  = pd.DataFrame({\"Panel\":[\"Panel A: Regression Imputation\",\"\",\"\",\"\"],\n",
    "                         \"Result Name\":[\"Pogrom 1349\",\"Ln(Pop 1925)\",\n",
    "                                        \"Pct Jewish 1925\",\"Pct Protestant 1925\"],\n",
    "                         \"Estimate\":np.round(beta[:-1],4),\n",
    "                         \"Standard Error\":np.round(beta_SE[:-1],4),\n",
    "                         \"Observations\":[int(N),\"\",\"\",\"\"],\n",
    "                         \"Adjusted R2\":[np.round(adjR2,4),\"\",\"\",\"\"]})\n",
    "panel_b  = pd.DataFrame({\"Panel\":[\"Panel B: Demographic Matching\"],\n",
    "                         \"Observations\":[int(N)],\n",
    "                         \"Adjusted R2\":[\"\"],\n",
    "                         \"Result Name\":[\"Pogrom 1349\"],\n",
    "                         \"Estimate\":[np.round(attB['att'],4)],\n",
    "                         \"Standard Error\":[np.round(att_seB['att'],4)]})\n",
    "panel_c  = pd.DataFrame({\"Panel\":[\"Panel C: Geographic Matching\"],\n",
    "                         \"Observations\":[int(N)],\n",
    "                         \"Adjusted R2\":[\"\"],\n",
    "                         \"Result Name\":[\"Pogrom 1349\"],\n",
    "                         \"Estimate\":[np.round(attC['att'],4)],\n",
    "                         \"Standard Error\":[np.round(att_seC['att'],4)]})\n",
    "replication_df = pd.concat((panel_a,panel_b,panel_c))\n",
    "replication_df.to_latex(\"./q4_replication_output/table6_replication.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Panel</th>\n",
       "      <th>Result Name</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Adjusted R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panel A: Regression Imputation</td>\n",
       "      <td>Pogrom 1349</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Ln(Pop 1925)</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0152</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Pct Jewish 1925</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0114</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Pct Protestant 1925</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0004</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panel B: Demographic Matching</td>\n",
       "      <td>Pogrom 1349</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>320</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panel C: Geographic Matching</td>\n",
       "      <td>Pogrom 1349</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>320</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Panel          Result Name  Estimate  \\\n",
       "0  Panel A: Regression Imputation          Pogrom 1349    0.0607   \n",
       "1                                         Ln(Pop 1925)    0.0390   \n",
       "2                                      Pct Jewish 1925    0.0135   \n",
       "3                                  Pct Protestant 1925    0.0003   \n",
       "0   Panel B: Demographic Matching          Pogrom 1349    0.0744   \n",
       "0    Panel C: Geographic Matching          Pogrom 1349    0.0819   \n",
       "\n",
       "   Standard Error Observations Adjusted R2  \n",
       "0          0.0226          320      0.0544  \n",
       "1          0.0152                           \n",
       "2          0.0114                           \n",
       "3          0.0004                           \n",
       "0          0.0192          320              \n",
       "0          0.0272          320              "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replication_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regressions and Matching on Various Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols1   = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','perc_CAT25','_const']    # Add Catholics\n",
    "X_cols2   = ['pog1349','logpop33_dep','perc_JEW33','perc_PROT25','perc_CAT25','_const'] # Change to '33 when possible\n",
    "X_cols3   = ['pog1349','perc_JEW25','perc_PROT25','perc_CAT25','_const']                # Only religion variables\n",
    "X_cols4   = ['pog1349','perc_Ag25','perc_Ind25','perc_Blue25','perc_self25','_const']   # Only labor variables\n",
    "X_cols5   = ['pog1349','logpop1300','nav_river','ruggedness20']                         # Only geographic/predetermined\n",
    "X_cols6   = ['pog1349','hephep_all',\n",
    "             'logpop1300','nav_river','ruggedness20','logpop25c',\n",
    "             'perc_JEW25','perc_PROT25','perc_CAT25',\n",
    "             'perc_Ag25','perc_Ind25','perc_Blue25','perc_self25','_const']             # Fully loaded regression\n",
    "X_cols    = [X_cols1,X_cols2,X_cols3,X_cols4,X_cols5,X_cols6]\n",
    "\n",
    "# Loop over all specifications\n",
    "betas         = []\n",
    "beta_SEs      = []\n",
    "Ns            = []\n",
    "match_atts    = []\n",
    "match_att_SEs = []\n",
    "for i in range(len(X_cols)):\n",
    "    \n",
    "    # Get df and XY matrices and parameters\n",
    "    reg_dfi,Xi,Yi,treatmentsi,Ni,Ki = get_XY_arrays(df,X_cols[i],Y_var,treat_var)\n",
    "    Ns.append(Ni)\n",
    "    \n",
    "    # Run regressions and save output\n",
    "    betai,beta_SEi = run_qje_regression(Xi,Yi,reg_dfi,X_cols[i],Y_var,clust_var,Ni,Ki)\n",
    "    betas.append(betai)\n",
    "    beta_SEs.append(beta_SEi)\n",
    "    \n",
    "    # Run matching procedure\n",
    "    X_matchi       = np.array(reg_dfi[X_cols[i][1:-1]])\n",
    "    dist_matrixi   = make_dist_matrix(X_matchi, Ni)\n",
    "    atti           = get_treatment_effect(X_matchi, dist_matrixi, treatmentsi, 4, Ni, ['att'])\n",
    "    att_sei        = bootstrap_match_SE(X_matchi, dist_matrixi, treatmentsi, 4, Ni, ['att'], 1000)\n",
    "    match_atts.append(atti)\n",
    "    match_att_SEs.append(att_sei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results to Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4d_df  = pd.DataFrame({\"Specification\":[\"1 - Include Catholic Share\",\n",
    "                                         \"2 - Change to 1933 Demographics\",\n",
    "                                         \"3 - Only Religion Variables\",\n",
    "                                         \"4 - Only Labor Variables\",\n",
    "                                         \"5 - Only Predetermined Variables\",\n",
    "                                         \"6 - Fully Loaded Regression\",],\n",
    "                         \"Regression Estimate\":np.round([betas[i][0] for i in range(len(betas))],4),\n",
    "                         \"Regression Standard Error\":np.round([beta_SEs[i][0] for i in range(len(beta_SEs))],4),\n",
    "                         \"Matching ATT Estimate\":np.round([match_atts[i]['att'] for i in range(len(match_atts))],4),\n",
    "                         \"Matching ATT Standard Error\":np.round([match_att_SEs[i]['att'] for i in range(len(match_att_SEs))],4),\n",
    "                         \"Observations\":[int(Ns[i]) for i in range(len(Ns))]})\n",
    "q4d_df.to_latex(\"./q4_replication_output/q4d_table.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity-Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariates for this exercise\n",
    "X_cols = ['pog1349','logpop25c','perc_JEW25','perc_PROT25','_const']\n",
    "reg_df,X,Y,treatments,N,K = get_XY_arrays(df,X_cols,Y_var,treat_var)\n",
    "\n",
    "# Get matrices for logistic regression\n",
    "Xlogit = X[:,1:]\n",
    "Ylogit = X[:,0][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(beta, Xlogit, Ylogit):\n",
    "    return -np.sum(Ylogit*(Xlogit @ beta[:,None]) + np.log((1.0 / ( 1.0 + np.exp(Xlogit @ beta[:,None])))))\n",
    "\n",
    "def logistic_gradient(beta, Xlogit, Ylogit):\n",
    "    p = 1.0 / ( 1.0 + np.exp(- Xlogit @ beta[:,None]))\n",
    "    return -(Xlogit.T @ (Ylogit-p)).ravel()\n",
    "\n",
    "# Optimize logistic regression and get propensity scores\n",
    "res = scipy.optimize.minimize(logistic_log_likelihood, x0=np.zeros(Xlogit.shape[1]), \n",
    "                              args=(Xlogit,Ylogit), method='BFGS', jac=logistic_gradient)\n",
    "betalogit  = res.x\n",
    "propscores = 1.0/(1.0 + np.exp(-(Xlogit @ betalogit[:,None])))\n",
    "reg_df['propensity_scores'] = propscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do propensity score matching\n",
    "X_match     = np.array(reg_df['propensity_scores'])[:,None]\n",
    "dist_matrix = make_dist_matrix(X_match, N, weight_type='identity')\n",
    "treats      = get_treatment_effect(X_match, dist_matrix, treatments, 4, N, ['att','atu','ate'])\n",
    "treat_ses   = bootstrap_match_SE(X_match, dist_matrix, treatments, 4, N, ['att','atu','ate'], 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results to Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propscore_df= pd.DataFrame({\"Parameter\":[\"ATT\",\"ATU\",\"ATE\"],\n",
    "                            \"Estimate\":np.round([treats['att'],treats['atu'],treats['ate']],4),\n",
    "                            \"Standard Error\":np.round([treat_ses['att'],treat_ses['atu'],treat_ses['ate']],4)})\n",
    "propscore_df.to_latex(\"./q4_replication_output/q4e_table.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propscore_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
